{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d8199ad-6ebe-481c-b32a-a5b4241e0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installations\n",
    "\n",
    "#! pip install bson\n",
    "#! pip install pandas\n",
    "#! pip install dirtyjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c11ba1-216b-4d7e-99de-cf60507f3a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import json, dirtyjson\n",
    "import csv\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92cc3b30-a287-4b61-9fae-18ca716b11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration\n",
    "\n",
    "file_path = 'data/4chan_online.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1307bcc0-97f9-4f77-823e-5fc74c077170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, usecols=['_id','posts', 'last_modified', 'archived', 'post_time_UTC', 'scraped_time_UTC', 'board_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42784eed-ebd4-456c-a920-80107c31c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "for i in range(len(df['posts'])):\n",
    "    line = df['posts'].iloc[i]\n",
    "    try:\n",
    "        json_line = json.loads(line)\n",
    "        posts.append(json_line)\n",
    "    except json.JSONDecodeError as e:\n",
    "        #print(f\"Error decoding JSON: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd18bfbd-3f6b-4278-b06f-a14787ad2306",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymous & 97.47\n",
      "Minifig & 0.04\n",
      "Translatorfag & 0.03\n",
      "sage & 0.03\n",
      "Lanu & 0.03\n",
      "justingod & 0.03\n",
      "OP & 0.02\n",
      "Greeble & 0.02\n",
      "RumicWorldStoryTime & 0.02\n",
      "cANON & 0.02\n",
      "QM & 0.02\n",
      "Dannyanon & 0.02\n",
      "Anonymous Mogul & 0.02\n",
      "AiWeaver & 0.02\n",
      "MedivhQM & 0.02\n",
      "DrDragonfagQM & 0.02\n",
      "No&#039;body & 0.02\n",
      "ar & 0.02\n",
      "GrandDragonQM & 0.02\n",
      "Mulrog & 0.02\n",
      "Contolist & 0.02\n",
      "Trips Namefag & 0.02\n",
      "Piggy & 0.01\n",
      "DOT DOT DOT & 0.01\n",
      "Builder_Referee & 0.01\n",
      "Gacha guy & 0.01\n",
      "fe2fucker & 0.01\n",
      "Billy & 0.01\n",
      "Cult of Passion & 0.01\n",
      "Magister & 0.01\n",
      "Our-Grandfather & 0.01\n",
      "Captain Kohai (Kancho Kohai) & 0.01\n",
      "Squig-Anon & 0.01\n",
      "ReptoidQM & 0.01\n",
      "TempQM & 0.01\n",
      "Lesches & 0.01\n",
      "@non & 0.01\n",
      "Krantagarh & 0.01\n",
      "Goggled Anon & 0.01\n",
      "Big Hat Steve & 0.01\n"
     ]
    }
   ],
   "source": [
    "# Users\n",
    "users = []\n",
    "for i in range(len(posts)):\n",
    "    for j in range(len(posts[i])):\n",
    "        p = posts[i][j]\n",
    "        if 'name' in p.keys(): \n",
    "            users.append(posts[i][j]['name'])\n",
    "totalUsers = len(users)\n",
    "from collections import Counter\n",
    "c = Counter(users)\n",
    "commonUsers = c.most_common()[:40]\n",
    "for user in commonUsers:\n",
    "    print(user[0] + ' & ' + str(round((user[1]/totalUsers)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d88779-85f4-47cc-b760-ef5639510aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posts length per board\n",
    "import re\n",
    "\n",
    "boardPosts = {}\n",
    "for i in range(len(df['posts'])):\n",
    "    line = df['posts'].iloc[i]\n",
    "    board = df['board_code'].iloc[i]\n",
    "    try:\n",
    "        json_line = json.loads(line)\n",
    "        if board in boardPosts.keys():\n",
    "            boardPosts[board].append(json_line)\n",
    "        else:\n",
    "            boardPosts[board] = [json_line]\n",
    "    except json.JSONDecodeError as e:\n",
    "        #print(f\"Error decoding JSON: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03190f3-401c-413a-8a99-7d16d8a31c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d1400e-aea8-472f-ba39-1ee985342d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "postMsgs = {}\n",
    "for k,discussions in boardPosts.items():\n",
    "    ls = []\n",
    "    for discussion in discussions:\n",
    "        for replies in discussion:\n",
    "            if 'com' in replies.keys():\n",
    "                com = replies['com']\n",
    "                com = re.sub('<[^<]+?>', '', com)\n",
    "                com = re.sub(r'http\\S+', '', com)\n",
    "                ls.append(com)       \n",
    "    ls.append(len(com))\n",
    "    postMsgs[k] = ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d89bd6f8-919b-4565-93a4-42d17d1b8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "postLengths = {}\n",
    "for k,v in postMsgs.items():\n",
    "    ls = []\n",
    "    for p in v:\n",
    "        cc = len(str(p))\n",
    "        ls.append(cc)\n",
    "    postLengths[k] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "078a4e02-aebe-4679-b8eb-e3595d8108a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dicMean = {}\n",
    "dicMedian = {}\n",
    "for k,v in postLengths.items():\n",
    "    dicMean[k] = np.mean(v)\n",
    "    dicMedian[k] = np.median(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b63fae3-61e8-4dc5-b9b7-675d81d440f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([20.0, 37.0, 38.0, 39.0, 40.0, 40.0, 42.0, 43.0, 44.0, 45.0, 47.0, 49.0, 51.0, 52.0, 53.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 60.0, 60.0, 61.0, 62.0, 62.0, 64.0, 67.0, 68.0, 68.0, 69.0, 70.0, 72.0, 72.0, 75.0, 75.0, 78.0, 79.0, 82.0, 85.0, 87.0, 87.0, 87.0, 87.0, 88.0, 89.0, 89.0, 90.0, 90.0, 91.0, 94.0, 94.0, 96.0, 102.0, 103.0, 106.0, 107.0, 107.0, 108.0, 112.0, 112.0, 114.0, 116.0, 118.0, 118.0, 120.0, 122.0, 122.0, 124.0, 125.0, 127.0, 129.0, 131.0, 144.0, 157.0, 163.0, 177.0, 210.0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedDicMean = {k: v for k, v in sorted(dicMean.items(), key=lambda item: item[1])}\n",
    "sortedDicMedian = {k: v for k, v in sorted(dicMedian.items(), key=lambda item: item[1])}\n",
    "sortedDicMedian.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b161211f-f86a-467f-9532-537ca673e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -q transformers\n",
    "#!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa67d675-45c2-4498-b8f7-a45b762fb897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\projects\\4chan\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\projects\\4chan\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a2e4064-adb3-4456-ae08-f29743fe5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sampledMsgs = dict.fromkeys(postMsgs.keys())\n",
    "for k,v in postMsgs.items():\n",
    "    if len(v) > 100:\n",
    "        sampledMsgs[k] = random.sample(postMsgs[k], 100)\n",
    "    else:\n",
    "        sampledMsgs[k] = postMsgs[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eca732b-be4c-414e-8c54-ae689fe3c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "dictSentiments = dict.fromkeys(sampledMsgs.keys(),[])\n",
    "#data = [\"I love you\", \"I hate you\"]\n",
    "for k,v in sampledMsgs.items():\n",
    "    ls = []\n",
    "    for com in v:\n",
    "        try:\n",
    "            ls.append(sentiment_task(com))\n",
    "        except:\n",
    "            continue\n",
    "    dictSentiments[k] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22ac8c1c-7de8-46e5-becd-7aae95b159a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictSentiLabels = dict.fromkeys(dictSentiments.keys(),[])\n",
    "for k,v in dictSentiments.items():\n",
    "    labels = [] \n",
    "    for lb in v:\n",
    "        labels.append(lb[0]['label']) \n",
    "    dictSentiLabels[k] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bda76bf-0dc4-43f2-b801-d4d353ef03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dictSentiLabels.items():\n",
    "    #print(k, v.count('positive'), v.count('neutral'), v.count('negative'))\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae980d7f-07e3-4850-b2fc-57d0fa161130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toxicity\n",
    "#!pip install detoxify\n",
    "from detoxify import Detoxify\n",
    "dictToxicity = dict.fromkeys(sampledMsgs.keys(), [])\n",
    "for k,v in sampledMsgs.items():\n",
    "    ls = []\n",
    "    for msg in v:\n",
    "        try:\n",
    "            results = Detoxify('original').predict(msg)\n",
    "        except:\n",
    "            continue\n",
    "        ls.append(results)\n",
    "    dictToxicity[k] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a04d05-80a3-46d8-92b7-f3ce155d6fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictToxicity['vt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "30c3288c-cb0c-4360-8b4d-18b709643a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total boards\n",
    "len(set(df['board_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48ab9099-0f2d-4bac-a881-519313bdb151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of all posts:  11642\n",
      "Count of all posts vs Anonymous posts:  1032012 vs 1002530\n",
      "total number of discussions:  11642\n",
      "discussions with unique no. of posts:  588\n"
     ]
    }
   ],
   "source": [
    "#all posts across all boards\n",
    "allposts = []\n",
    "for i in range(len(df['posts'])):\n",
    "    allposts.append(df['posts'][i].count('}'))\n",
    "print('Count of all posts: ', len(allposts))\n",
    "\n",
    "#all posts across all boards with Anonymous user\n",
    "AnonymousPosts = 0\n",
    "for i in range(len(df['posts'])):\n",
    "    val = df['posts'][i].count('Anonymous')\n",
    "    if  val > 0:\n",
    "        AnonymousPosts += val\n",
    "print('Count of all posts vs Anonymous posts: ', sum(allposts), 'vs', AnonymousPosts)\n",
    "\n",
    "#Key as no of posts - value no of discussions\n",
    "postsBins = {}\n",
    "for pp in allposts:\n",
    "    if pp in postsBins.keys():\n",
    "        postsBins[pp] += 1\n",
    "    else:\n",
    "        postsBins[pp] = 1\n",
    "print('total number of discussions: ', sum(postsBins.values()))\n",
    "print('discussions with unique no. of posts: ', len(postsBins.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c7c4fe58-6ce4-42c5-881d-fece83b3903a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 141, 100: 564, 200: 15, 300: 4, 400: 3, 500: 2}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seperating discussions with number of posts into fixed bins \n",
    "# [0 posts, less than 100 posts, between 100-199 posts, between 200-299 posts, between 300-399 posts, 400+ posts]\n",
    "hundbins = {0: 0, 100: 0, 200: 0, 300: 0, 400: 0, 500:0}\n",
    "for k, v in postsBins.items():\n",
    "    if v == 1:\n",
    "        hundbins[0] += 1\n",
    "    if v < 100:\n",
    "        hundbins[100] += 1\n",
    "    if v >= 100 and v < 200:\n",
    "        hundbins[200] += 1\n",
    "    if v >= 200 and v < 300:\n",
    "        hundbins[300] += 1\n",
    "    if v >= 300 and v < 400:\n",
    "        hundbins[400] += 1\n",
    "    if v >= 400:\n",
    "        hundbins[500] += 1\n",
    "hundbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c9c8c4ed-ff86-4664-bc42-3e57aee049b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.34156378600823,\n",
       " 77.36625514403292,\n",
       " 2.05761316872428,\n",
       " 0.5486968449931412,\n",
       " 0.411522633744856,\n",
       " 0.2743484224965706]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = sum(hundbins.values())\n",
    "hundbinpc = []\n",
    "for k, v in hundbins.items():\n",
    "    hundbinpc.append((v/tot)*100)\n",
    "hundbinpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "af8da2c5-d5ad-46d3-91d5-5069186db615",
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = df.groupby('board_code')\n",
    "board_codes = list(set(df['board_code']))\n",
    "len(board_codes)\n",
    "\n",
    "scores = []\n",
    "for bc in board_codes:\n",
    "    scores.append(boards.get_group(bc).count().iloc[0])\n",
    "\n",
    "scores.sort()    \n",
    "#scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54f9e9-4257-4026-923b-7dfcfa179f3d",
   "metadata": {},
   "source": [
    "Posts analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "898d311a-e2ca-4a8c-b502-36853a31a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def cleanJSON(dirty_json):\n",
    "    regex_replace = [(r\"([ \\{,:\\[])(u)?'([^']+)'\", r'\\1\"\\3\"'), (r\" False([, \\}\\]])\", r' false\\1'), (r\" True([, \\}\\]])\", r' true\\1')]\n",
    "    for r, s in regex_replace:\n",
    "        dirty_json = re.sub(r, s, dirty_json)\n",
    "    dirty_json.replace('\\\\', '')\n",
    "    clean_json = json.loads(dirty_json)\n",
    "    return clean_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79305830-db75-4d05-97ed-52637c2571b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# as per recommendation from @freylis, compile once only\n",
    "CLEANR = re.compile('<.*?>') \n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleantext = re.sub(CLEANR, '', raw_html)\n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66bd85e2-0fb5-446d-ab10-dc3580c54dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion titles vs no. of posts\n",
    "\n",
    "dicTitlesPosts = {}\n",
    "for d in range(len(df['posts'])):\n",
    "    #print(d)\n",
    "    currPost = df['posts'][d]\n",
    "    board = df['board_code'][d]\n",
    "    #specific dirty cases\n",
    "    count = currPost.count('}')\n",
    "    ind1 = currPost.find(\"sub\")+6\n",
    "    ind2 = currPost[ind1:].find(\"\\\"\")\n",
    "    title = board+\"-\"+currPost[ind1:ind1+ind2]\n",
    "    if title not in dicTitlesPosts.keys():\n",
    "        dicTitlesPosts[title] = count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "53ce958e-6e57-4433-8b4f-95c63a26a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = dict(sorted(dicTitlesPosts.items(), key=lambda item: item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9dbfbd71-9a02-4d05-89b6-a074e49e9275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmg-Dokkan Battle 1562\n",
      "h-hdg/ Hentai Diffusion General #536 1359\n",
      "qst-The King &amp; Queen of /QST/: Nominations, Qualifications, &amp; Preparations 1339\n",
      "vm-/cs2g/CS2/CSGO/Counter-Strike Esports discussion ESL Pro League XIX edition 1293\n",
      "qst-QTG: Easter Edition 1260\n",
      "sp-/cyc/ - Giro d&#039;Italia - Stage 1 1155\n",
      "qst-HERO(&#039;s party member) QUEST 1038\n",
      "u-General Yuri Discussion Thread 1005\n",
      "vmg-Fire Emblem Heroes 1003\n",
      "vm-/Bombergirl/ General「ボンバーガール」 997\n",
      "qst-Warlords of Chaos #1 981\n",
      "vmg-Genshin Impact 925\n",
      "u-Recent Yuri Releases 913\n",
      "vg-/@/ - The iDOLM@STER General 912\n",
      "vmg-Blue Archive JP 893\n",
      "jp-DJT - Daily Japanese Thread #3855 884\n",
      "vmg-Aether Gazer 878\n",
      "vg-/vn/ - Completed Edition 870\n",
      "vg-/tekgen/ - Tekken General 858\n",
      "jp-hololive 843\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for k,v in sorted_dict.items():\n",
    "    print(k,v)\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9f255fcd-8da8-4fd7-a2a7-5a2851bf4f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"no\":1,\"sticky\":1,\"closed\":1,\"now\":\"080720Fri06:50:24\",\"name\":\"Anonymous\",\"sub\":\"Welcome to vmg  VidyaMobile Games\",\"com\":\"vmg is a place to discuss all types of mobile games, including both Android and iOS, phones and tablets Please note that Nintendo and Sony handhelds are considered consoles, and that threads pertaining to those platforms and their gaming titles should be posted elsewherebrnbrnDoes this mean discussion of mobile games is banned on other video game boards span style=\"fontsize:15pxfontweight:bold\"Nospan vmg is just a separate board specifically focused on mobile games where discussions about your favorite games can thrivebrnbrnPlease familiarize yourself with a href=\"https:www4channelorgrulesvmg\"the rulesa and remember to a href=\"https:www4channelorgfaqspoiler\"use the spoiler function where appropriateabrnnp style=\"fontsize:15pxfontweight:bold\"Please note that, like v, quotGeneralsquotlongterm, oneaftertheother, recurring threads about a specific game are not permitted on vmg Such threads belong on a href=\"https:boards4channelorgvg\"a href=\"boards4channelorgvg\" class=\"quotelink\"gtgtgtvgaap\",\"filename\":\"vmg\",\"ext\":\"png\",\"w\":240,\"h\":240,\"tnw\":240,\"tnh\":240,\"tim\":1596797424824,\"time\":1596797424,\"md5\":\"709htKZ6LVTp9xFjODSg==\",\"fsize\":116949,\"resto\":0,\"capcode\":\"mod\",\"semanticurl\":\"welcometovmgvidyamobilegames\",\"customspoiler\":3,\"replies\":0,\"images\":0,\"uniqueips\":1}]\n",
      "[{\"no\":1,\"sticky\":1,\"closed\":1,\"now\":\"080720Fri06:50:24\",\"name\":\"Anonymous\",\"sub\":\"Welcome to vmg  VidyaMobile Games\",\"com\":\"vmg is a place to discuss all types of mobile games, including both Android and iOS, phones and tablets Please note that Nintendo and Sony handhelds are considered consoles, and that threads pertaining to those platforms and their gaming titles should be posted elsewherebrnbrnDoes this mean discussion of mobile games is banned on other video game boards span style=\"fontsize:15pxfontweight:bold\"Nospan vmg is just a separate board specifically focused on mobile games where discussions about your favorite games can thrivebrnbrnPlease familiarize yourself with a href=\"https:www4channelorgrulesvmg\"the rulesa and remember to a href=\"https:www4channelorgfaqspoiler\"use the spoiler function where appropriateabrnnp style=\"fontsize:15pxfontweight:bold\"Please note that, like v, quotGeneralsquotlongterm, oneaftertheother, recurring threads about a specific game are not permitted on vmg Such threads belong on a href=\"https:boards4channelorgvg\"a href=\"boards4channelorgvg\" class=\"quotelink\"gtgtgtvgaap\",\"filename\":\"vmg\",\"ext\":\"png\",\"w\":240,\"h\":240,\"tnw\":240,\"tnh\":240,\"tim\":1596797424824,\"time\":1596797424,\"md5\":\"709htKZ6LVTp9xFjODSg==\",\"fsize\":116949,\"resto\":0,\"capcode\":\"mod\",\"semanticurl\":\"welcometovmgvidyamobilegames\",\"customspoiler\":3,\"replies\":0,\"images\":0,\"uniqueips\":1}]\n",
      "[{\"no\":1,\"sticky\":1,\"closed\":1,\"now\":\"080720Fri06:50:24\",\"name\":\"Anonymous\",\"sub\":\"Welcome to vmg  VidyaMobile Games\",\"com\":\"vmg is a place to discuss all types of mobile games, including both Android and iOS, phones and tablets Please note that Nintendo and Sony handhelds are considered consoles, and that threads pertaining to those platforms and their gaming titles should be posted elsewherebrnbrnDoes this mean discussion of mobile games is banned on other video game boards span style=\"fontsize:15pxfontweight:bold\"Nospan vmg is just a separate board specifically focused on mobile games where discussions about your favorite games can thrivebrnbrnPlease familiarize yourself with a href=\"https:www4channelorgrulesvmg\"the rulesa and remember to a href=\"https:www4channelorgfaqspoiler\"use the spoiler function where appropriateabrnnp style=\"fontsize:15pxfontweight:bold\"Please note that, like v, quotGeneralsquotlongterm, oneaftertheother, recurring threads about a specific game are not permitted on vmg Such threads belong on a href=\"https:boards4channelorgvg\"a href=\"boards4channelorgvg\" class=\"quotelink\"gtgtgtvgaap\",\"filename\":\"vmg\",\"ext\":\"png\",\"w\":240,\"h\":240,\"tnw\":240,\"tnh\":240,\"tim\":1596797424824,\"time\":1596797424,\"md5\":\"709htKZ6LVTp9xFjODSg==\",\"fsize\":116949,\"resto\":0,\"capcode\":\"mod\",\"semanticurl\":\"welcometovmgvidyamobilegames\",\"customspoiler\":3,\"replies\":0,\"images\":0,\"uniqueips\":1}]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 494 (char 493)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposts\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposts\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m     posts \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mposts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m posts:\n\u001b[0;32m     10\u001b[0m         users\u001b[38;5;241m.\u001b[39mappend(post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 494 (char 493)"
     ]
    }
   ],
   "source": [
    "# User names\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "users = []\n",
    "for i in range(len(df['posts'])):\n",
    "    print(df['posts'][2])\n",
    "    posts = json.loads(df['posts'][i])\n",
    "    for post in posts:\n",
    "        users.append(post['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba8ee289-825c-4819-bee9-253c54d25460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Anonymous\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# User names\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "count = 0\n",
    "hasImage = 0\n",
    "msg = []\n",
    "for i in range(len(df['posts'])):\n",
    "    a = pd.read_json(df['posts'][i])\n",
    "    a = a['name']\n",
    "    print(a.head())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d59965-ecd2-49c5-be56-f3a4fddd83a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3038562, 3038562)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count, hasImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "4ea36406-3b16-4f2a-b736-500ea568c2a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[358], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmsg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "msg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954310c-8019-450d-ab86-02cfea3c335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e25b61-abf8-4dfe-952d-295b5e670368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b8a5e-5795-4c14-873f-4751c067b211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "974862c5-918c-4e49-89a4-3e12aa1a2275",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Invalid \\escape: line 1 column 56469 (char 56468)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[331], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m a \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposts\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[0;32m      6\u001b[0m a \u001b[38;5;241m=\u001b[39m cleanhtml(a)\n\u001b[1;32m----> 7\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mcleanJSON\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m a \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(a)\n\u001b[0;32m      9\u001b[0m dfposts \u001b[38;5;241m=\u001b[39m dirtyjson\u001b[38;5;241m.\u001b[39mloads(a)\n",
      "Cell \u001b[1;32mIn[330], line 9\u001b[0m, in \u001b[0;36mcleanJSON\u001b[1;34m(dirty_json)\u001b[0m\n\u001b[0;32m      7\u001b[0m     dirty_json \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(r, s, dirty_json)\n\u001b[0;32m      8\u001b[0m dirty_json\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m clean_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirty_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_json\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Invalid \\escape: line 1 column 56469 (char 56468)"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "hasImage = 0\n",
    "msg = []\n",
    "for i in range(len(df['posts'])):\n",
    "    a = df['posts'][i]\n",
    "    a = cleanhtml(a)\n",
    "    a = cleanJSON(a)\n",
    "    a = json.dumps(a)\n",
    "    dfposts = dirtyjson.loads(a)\n",
    "    for j in range(len(dfposts)):\n",
    "        #print(dfposts[j]['filename'])\n",
    "        #print(dfposts[j]['com'])\n",
    "        count += 1\n",
    "        \n",
    "        if 'filename' in dfposts[j]:\n",
    "            hasImage += 1\n",
    "        if 'com' in dfposts[j]:\n",
    "            msg.append(dfposts[j]['com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4ccc252b-26a3-4277-a981-d17b6cdf3f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " 20,\n",
       " ['Please post more pics like this. Thanks anons.',\n",
       "  '<a href=\"#p2185924\" class=\"quotelink\">&gt;&gt;2185924</a><br>ill post some more if this is still up. ive been awake 23hrs and am going to bed. also ask in the ak anime thread on <span class=\"deadlink\">&gt;&gt;&gt;/k/47495512</span>',\n",
       "  '<a href=\"#p2185924\" class=\"quotelink\">&gt;&gt;2185924</a>',\n",
       "  '<a href=\"#p2185924\" class=\"quotelink\">&gt;&gt;2185924</a>'])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count, hasImage, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899fb4e4-9e96-452f-b44b-8c3386f3f972",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'postMsgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Sentiment analysis of posts\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mpostMsgs\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'postMsgs' is not defined"
     ]
    }
   ],
   "source": [
    "# Sentiment analysis of posts\n",
    "\n",
    "len(postMsgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c648b-0683-4f00-86b9-63f6ada8bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -q transformers\n",
    "#! pip install tensorflow\n",
    "#!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "#! pip install -q distutils\n",
    "!pip uninstall tensorflow\n",
    "!pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cbc30ea-f1d2-4e76-aa00-b113fddc78fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\projects\\4chan\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m----> 3\u001b[0m sentiment_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment-analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI love you\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI hate you\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m sentiment_pipeline(data)\n",
      "File \u001b[1;32mC:\\projects\\4chan\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:906\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    905\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 906\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    917\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mC:\\projects\\4chan\\Lib\\site-packages\\transformers\\pipelines\\base.py:234\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    240\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28381d-abf1-41cd-b248-139102adff0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d055df6-f672-4ba8-8333-c3c6169c1999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5d3f3-3b9c-4143-a8fd-c00a6b19b101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d3da4-d969-4ea9-98c8-0052379175f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fd1e2-2dd2-45d0-acf3-badfdef73cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89edc544-3b02-4fb3-96af-0eeb071e1951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion titles vs no. of posts\n",
    "\n",
    "titles_posts = {}\n",
    "for d in range(len(df['posts'])):\n",
    "    posts = json.loads(df['posts'][2000])\n",
    "    postscount = len(posts)\n",
    "    for post in posts:\n",
    "        dfpost = pd.DataFrame.from_dict(post, orient='index')\n",
    "        #print(len(dfpost))\n",
    "        #print(dfpost)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f99907a-6492-4e8b-a803-f2f9d9062162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11642"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c46095-622d-45b2-b4d2-321d775bfb61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
